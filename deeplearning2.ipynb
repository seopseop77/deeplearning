{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sXubHLLkWu2t"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전 결합층의 부모 클래스 \n",
        "class BaseLayer:\n",
        "  def update(self,eta): # 경사하강법 \n",
        "    self.w -= eta * self.grad_w\n",
        "    self.b -= eta * self.grad_b"
      ],
      "metadata": {
        "id": "Z91HC8s7W9SO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --은닉층-- \n",
        "class MiddleLayer(BaseLayer):\n",
        "  def __init__(self,n_upper,n):\n",
        "    # He 초깃값 사용 , n_upper : 앞 층의 뉴런 수 , n : 해당 층의 뉴런 수 \n",
        "    self.w = np.random.randn(n_upper,n) * np.sqrt(2/n_upper)\n",
        "    self.b = np.zeros(n)\n",
        "\n",
        "  def forward(self,x): # 순전파 구현 \n",
        "    self.x = x \n",
        "    self.u = np.dot(x, self.w) + self.b\n",
        "    self.y = np.where(self.u <= 0 , 0, self.u ) # ReLU 함수 \n",
        "\n",
        "  def backward(self,grad_y): # 역전파 구현 \n",
        "    delta = grad_y * np.where(self.u<=0 , 0 , 0 , 1) # ReLU 의 편미분 값을 곱해줌 \n",
        "    \n",
        "    self.grad_w = np.dot(self.x.T, delta)\n",
        "    self.grad_b = np.sum(delta,axis = 0) # 각 열에 있는 수를 더함 \n",
        "    self.grad_x = np.dot(delta, self.w.T)"
      ],
      "metadata": {
        "id": "7XVaeZV2XS9Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력층 \n",
        "class OutputLayer(BaseLayer):\n",
        "  def __init__(self,n_upper,n):\n",
        "    # 자비에르 초기화 기반의 초깃값 \n",
        "    self.w = np.random.randn(n_upper,n) / np.sqrt(n_upper)\n",
        "    self.b = np.zeros(n)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    self.x = x\n",
        "    u = np.dot(x,self.w) + self.b\n",
        "    # 소프트 맥스 함수 \n",
        "    self.y = np.exp(u)/np.sum(np.exp(u), axis = 1, keepdims = True) # axis를 1로 지정해 각 샘플마다 총합을 구하고 keepdims = True 로 하여 배열의 차원을 유지 \n",
        "    # self.y = np.exp(u-np.max(u))/np.sum(np.exp(u-np.max()), axis = 1 , keepdims = True) # 지수함수의 오버플로우를 막기 위한 코드 \n",
        "\n",
        "  def backward(self,t):\n",
        "    delta = self.y - t # 수식적으로 정리해낸 값, t는 각 출력에 대응하는 실제 정답이다. \n",
        "\n",
        "    self.grad_w = np.dot(self.x.T, delta)\n",
        "    self.grad_b = np.sum(delta,axis = 0) \n",
        "    self.grad_x = np.dot(delta, self.w.T)\n"
      ],
      "metadata": {
        "id": "UkRK9LGxZBRP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jqvU81UNacFM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}